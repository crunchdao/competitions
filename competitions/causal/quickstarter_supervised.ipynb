{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1c7016-a6f4-431b-9e1f-28d234c934d6",
   "metadata": {},
   "source": [
    "This notebook is a quickstarter for DataCrunching. It is a collection of code snippets and explanations to get you started with the Causality Discovery code competition. It should give you a good starting point to understand how to work with the Crunch Foundation infrastructure.\n",
    "\n",
    "It shows how to load the data, how to create a submission file and how to submit it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747410f3",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "\n",
    "- Environment variables are configured to specify the API and web base URLs.\n",
    "- The `crunch-cli` package is upgraded to the latest version.\n",
    "- The notebook is set up to interact with the competition using a provided token.Update the token via https://hub.crunchdao.io/competitions/causality-discovery/submit/via/notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e792f933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: API_BASE_URL=http://api.hub.crunchdao.io\n",
      "env: WEB_BASE_URL=http://hub.crunchdao.io\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "%env API_BASE_URL=http://api.hub.crunchdao.io\n",
    "%env WEB_BASE_URL=http://hub.crunchdao.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e7bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: crunch-cli in /home/skhotijah/.local/lib/python3.10/site-packages (3.17.2)\n",
      "Requirement already satisfied: astor in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (0.8.1)\n",
      "Requirement already satisfied: click in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (8.1.7)\n",
      "Requirement already satisfied: coloredlogs in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (15.0.1)\n",
      "Requirement already satisfied: dataclasses-json in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (0.6.7)\n",
      "Requirement already satisfied: gitignorefile in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.1.2)\n",
      "Requirement already satisfied: humanfriendly in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (10.0)\n",
      "Requirement already satisfied: inflection in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (0.5.1)\n",
      "Requirement already satisfied: inquirer in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (3.3.0)\n",
      "Requirement already satisfied: joblib in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.4.2)\n",
      "Requirement already satisfied: networkx in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (3.3)\n",
      "Requirement already satisfied: packaging in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (24.1)\n",
      "Requirement already satisfied: pandas in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (2.2.2)\n",
      "Requirement already satisfied: psutil in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (6.0.0)\n",
      "Requirement already satisfied: pyarrow in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (16.1.0)\n",
      "Requirement already satisfied: pytest in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (8.3.1)\n",
      "Requirement already satisfied: python-dotenv in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.0.1)\n",
      "Requirement already satisfied: requests in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.0.0)\n",
      "Requirement already satisfied: requirements-parser in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (0.10.1)\n",
      "Requirement already satisfied: scikit-learn in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.5.0)\n",
      "Requirement already satisfied: scipy in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.14.0)\n",
      "Requirement already satisfied: sseclient-py in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (1.8.0)\n",
      "Requirement already satisfied: tqdm in /home/skhotijah/.local/lib/python3.10/site-packages (from crunch-cli) (4.66.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from dataclasses-json->crunch-cli) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from dataclasses-json->crunch-cli) (0.9.0)\n",
      "Requirement already satisfied: blessed>=1.19.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from inquirer->crunch-cli) (1.20.0)\n",
      "Requirement already satisfied: editor>=1.6.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from inquirer->crunch-cli) (1.6.6)\n",
      "Requirement already satisfied: readchar>=3.0.6 in /home/skhotijah/.local/lib/python3.10/site-packages (from inquirer->crunch-cli) (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/skhotijah/.local/lib/python3.10/site-packages (from pandas->crunch-cli) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/skhotijah/.local/lib/python3.10/site-packages (from pandas->crunch-cli) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/skhotijah/.local/lib/python3.10/site-packages (from pandas->crunch-cli) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/skhotijah/.local/lib/python3.10/site-packages (from pandas->crunch-cli) (2024.1)\n",
      "Requirement already satisfied: iniconfig in /home/skhotijah/.local/lib/python3.10/site-packages (from pytest->crunch-cli) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/skhotijah/.local/lib/python3.10/site-packages (from pytest->crunch-cli) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/skhotijah/.local/lib/python3.10/site-packages (from pytest->crunch-cli) (1.2.1)\n",
      "Requirement already satisfied: tomli>=1 in /home/skhotijah/.local/lib/python3.10/site-packages (from pytest->crunch-cli) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/skhotijah/.local/lib/python3.10/site-packages (from requests->crunch-cli) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->crunch-cli) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/skhotijah/.local/lib/python3.10/site-packages (from requests->crunch-cli) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->crunch-cli) (2019.11.28)\n",
      "Requirement already satisfied: types-setuptools>=69.1.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from requirements-parser->crunch-cli) (71.1.0.20240724)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from scikit-learn->crunch-cli) (3.5.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/lib/python3/dist-packages (from blessed>=1.19.0->inquirer->crunch-cli) (0.1.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from blessed>=1.19.0->inquirer->crunch-cli) (1.14.0)\n",
      "Requirement already satisfied: runs in /home/skhotijah/.local/lib/python3.10/site-packages (from editor>=1.6.0->inquirer->crunch-cli) (1.2.2)\n",
      "Requirement already satisfied: xmod in /home/skhotijah/.local/lib/python3.10/site-packages (from editor>=1.6.0->inquirer->crunch-cli) (1.8.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/skhotijah/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->crunch-cli) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/skhotijah/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->crunch-cli) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "---\n",
      "Your token seems to have expired or is invalid.\n",
      "\n",
      "Please follow this link to copy and paste your new setup command:\n",
      "http://hub.crunchdao.io/competitions/causality-discovery/submit\n",
      "\n",
      "If you think that is an error, please contact an administrator.\n"
     ]
    }
   ],
   "source": [
    "# Upgrade crunch-cli\n",
    "%pip install crunch-cli --upgrade\n",
    "\n",
    "# Setup crunch-cli with token\n",
    "!crunch setup --notebook causality-discovery default --token cjMlVzlafiyv0F8YxrUsQ8SSTJJ2aoXTdMDKYq0sAnoXMoENm7VrxXxE5NgFTOUx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5afc9",
   "metadata": {},
   "source": [
    "## Import\n",
    "IMPORTANT: For each library import, in order to avoid any issue related to the library version, it is strongly recommended to specify the version of the library you are using. This to ensure that the notebook will be reproducible in the Crunch Foundation environment without any undesirable modification to the behavior of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2e4fdd-0b2c-4f7d-b93a-58fd2bbb4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import crunch\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e30cb-8d7f-4c69-8c58-5e06ea88fd68",
   "metadata": {},
   "source": [
    "## Loading all datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77ed3a",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8ab4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded inline runner with module: <module '__main__'>\n",
      "download data/X_train.pickle from https://crunchdao--competition--staging.s3.eu-west-1.amazonaws.com/data-releases/34/X_train.pickle (7591133 bytes)\n",
      "already exists: file length match\n",
      "download data/y_train.pickle from https://crunchdao--competition--staging.s3.eu-west-1.amazonaws.com/data-releases/34/y_train.pickle (98523 bytes)\n",
      "already exists: file length match\n",
      "download data/X_test.pickle from https://crunchdao--competition--staging.s3.eu-west-1.amazonaws.com/data-releases/34/X_test_reduced.pickle (329528 bytes)\n",
      "already exists: file length match\n",
      "download data/y_test.pickle from https://crunchdao--competition--staging.s3.eu-west-1.amazonaws.com/data-releases/34/y_test_reduced.pickle (4935 bytes)\n",
      "already exists: file length match\n",
      "download data/example_prediction.parquet from https://crunchdao--competition--staging.s3.eu-west-1.amazonaws.com/data-releases/34/example_prediction_reduced.parquet (3939 bytes)\n",
      "already exists: file length match\n"
     ]
    }
   ],
   "source": [
    "# Load data using Crunch\n",
    "crunch = crunch.load_notebook()\n",
    "X_train, y_train, X_test = crunch.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfaa0d",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "For each variable in each dataset, we create a vector of features based on the relationship between that variable and - for example - `X` or `Y`, such has the correlation value, or the result of a T-test given a certain $p$-value threshold (1 = null hypothesis rejected, 0 = not rejected).\n",
    "\n",
    "\n",
    "The architecture is extensible, to have an idea on how to create new features. In short, each family of features (called feature set), such as *correlation*, loads all the files one by one and creates the desired correlation-based features. All feature sets are merged at the end to create `Xy` matching dataset and varialble in the join. The computation of a feature set is parallelized. In this way, if some feature sets are slow, we can save them and load at a later stage and just spend time to create new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90265718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "from sklearn.linear_model import Ridge, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from dcor import distance_correlation\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from itertools import combinations, product\n",
    "from functools import reduce\n",
    "from pingouin.correlation import partial_corr\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import ttest_rel, pearsonr, spearmanr\n",
    "from dcor.homogeneity import energy_test\n",
    "\n",
    "\n",
    "\n",
    "# This dictionary maps graph structures into our class labels:\n",
    "r = defaultdict(str)\n",
    "r[(0,0,0,1)] = 'Cause of X'\n",
    "r[(1,0,0,0)] = 'Consequence of X'\n",
    "r[(0,0,1,1)] = 'Confounder'\n",
    "r[(1,1,0,0)] = 'Collider'\n",
    "r[(1,0,1,0)] = 'Mediator'\n",
    "r[(0,0,0,0)] = 'Independent'\n",
    "r[(0,0,1,0)] = 'Cause of Y'\n",
    "r[(0,1,0,0)] = 'Consequence of Y'\n",
    "\n",
    "\n",
    "def get_labels(A):\n",
    "    \"\"\"\n",
    "    Classify the nodes of A as \"collider\", \"confounder\", etc., wrt the edge X→Y\n",
    "\n",
    "    For each node i, we look at the role of i wrt X→Y, ignoring all other nodes.\n",
    "    There are 8 possible cases:\n",
    "    - Cause of X\n",
    "    - Consequence of X\n",
    "    - Confounder\n",
    "    - Collider\n",
    "    - Mediator\n",
    "    - Independent\n",
    "    - Cause of Y\n",
    "    - Consequence of Y\n",
    "\n",
    "    Caveat:\n",
    "    - The notions of \"confounder\", \"collider\", etc. only make sense for small, textbook graphs.\n",
    "\n",
    "    Input:  A: adjacency_matrix\n",
    "    Output: dictionary, with the edges as keys (excluding 'X' and 'Y'), and class as value\n",
    "\n",
    "    \"\"\"\n",
    "    global r\n",
    "    res = {}\n",
    "    for node in A.columns:\n",
    "        if node in \"XY\":\n",
    "            continue\n",
    "        B = A.loc[('X','Y',node),:].loc[:,('X','Y',node)]\n",
    "        res[node] = r[ tuple( B.values[ [0,1,2,2], [2,2,1,0] ] ) ]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def ttest(dataset, pvalue_threshold=0.05):\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        ttest_vX = ttest_rel(dataset[variable], dataset[\"X\"])\n",
    "        ttest_vY = ttest_rel(dataset[variable], dataset[\"Y\"])\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"ttest(v,X)\": ttest_vX.statistic,\n",
    "            f\"pvalue(ttest(v,X))<={pvalue_threshold}\": (ttest_vX.pvalue <= pvalue_threshold).astype(float),\n",
    "            \"ttest(v,Y)\": ttest_vY.statistic,\n",
    "            f\"pvalue(ttest(v,Y))<={pvalue_threshold}\": (ttest_vY.pvalue <= pvalue_threshold).astype(float),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    ttest_XY = ttest_rel(dataset[\"X\"], dataset[\"Y\"])\n",
    "    df[\"ttest(X,Y)\"] = ttest_XY.statistic\n",
    "    df[f\"pvalue(ttest(X,Y))<={pvalue_threshold}\"] = (ttest_XY.pvalue <= pvalue_threshold).astype(float)\n",
    "    # some the ttest returns NaN when the variance is 0, so we fill with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pearson_correlation(dataset):\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        tmp = dataset.corr().drop([variable], axis=\"columns\").loc[variable].abs()  # TODO: this can be computed just ones at the beginning and then sliced at each iteration\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"corr(v,X)\": dataset[[variable, \"X\"]].corr().loc[variable, \"X\"],\n",
    "            \"corr(v,Y)\": dataset[[variable, \"Y\"]].corr().loc[variable, \"Y\"],\n",
    "            \"max(corr(v, others))\": tmp.max(),\n",
    "            \"min(corr(v, others))\": tmp.min(),\n",
    "            \"mean(corr(v, others))\": tmp.mean(),\n",
    "            \"std(corr(v, others))\": tmp.std(),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr().loc[\"X\", \"Y\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def pearson_correlation2(dataset):\n",
    "    \"\"\"Same as correlation but excluding X and Y in max, min, mean, std computations.\n",
    "\n",
    "    Note: nothing really changes in the results of the classification task.\n",
    "    \"\"\"\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        tmp = dataset[variables].corr().drop([variable], axis=\"columns\").loc[variable].abs()\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"corr(v,X)\": dataset[[variable, \"X\"]].corr().loc[variable, \"X\"],\n",
    "            \"corr(v,Y)\": dataset[[variable, \"Y\"]].corr().loc[variable, \"Y\"],\n",
    "            \"max(corr(v, others))\": tmp.max(),\n",
    "            \"min(corr(v, others))\": tmp.min(),\n",
    "            \"mean(corr(v, others))\": tmp.mean(),\n",
    "            \"std(corr(v, others))\": tmp.std(),\n",
    "        }\n",
    "        if len(tmp) == 1:\n",
    "            d[\"std(corr(v, others))\"] = 0.0\n",
    "        elif len(tmp) == 0:\n",
    "            d[\"max(corr(v, others))\"] = 0.0\n",
    "            d[\"min(corr(v, others))\"] = 0.0\n",
    "            d[\"mean(corr(v, others))\"] = 0.0\n",
    "            d[\"std(corr(v, others))\"] = 0.0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr().loc[\"X\", \"Y\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def pearson_correlation_test(dataset, pvalue_threshold=0.05):\n",
    "    \"\"\"Same as correlation2 but with significance tests (pvalue <= pvalue_threshold)\n",
    "    \"\"\"\n",
    "    variables = dataset.columns # .drop([\"X\", \"Y\"])\n",
    "    corr_pvalue = pd.DataFrame(\n",
    "        index=pd.MultiIndex.from_tuples(product(variables, variables)),\n",
    "        columns=[\"correlation\", \"pvalue\"],\n",
    "    )\n",
    "    for variable1, variable2 in corr_pvalue.index:\n",
    "        corr_pvalue.loc[(variable1, variable2), \"correlation\"], corr_pvalue.loc[(variable1, variable2), \"pvalue\"] = pearsonr(dataset[variable1], dataset[variable2])\n",
    "\n",
    "    correlations = corr_pvalue.reset_index().pivot(index=\"level_0\", columns=\"level_1\", values=\"correlation\")\n",
    "    pvalues_test = (corr_pvalue.reset_index().pivot(index=\"level_0\", columns=\"level_1\", values=\"pvalue\") <= pvalue_threshold).astype(float)\n",
    "\n",
    "    df = []\n",
    "    for variable in variables.drop([\"X\", \"Y\"]):\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"pearson(v,X)\": correlations.loc[variable, \"X\"],\n",
    "            f\"pvalue(pearson(v,X))<={pvalue_threshold}\": pvalues_test.loc[variable, \"X\"],\n",
    "            \"pearson(v,Y)\": correlations.loc[variable, \"Y\"],\n",
    "            f\"pvalue(pearson(v,Y))<={pvalue_threshold}\": pvalues_test.loc[variable, \"Y\"],\n",
    "            \"max(pearson(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().max(),\n",
    "            \"min(pearson(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().min(),\n",
    "            \"mean(pearson(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().mean(),\n",
    "            \"std(pearson(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().std(),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"pearson(X,Y)\"] = correlations.loc[\"X\", \"Y\"]\n",
    "    df[f\"pvalue(pearson(X,Y))<={pvalue_threshold}\"] = pvalues_test.loc[\"X\", \"Y\"]\n",
    "    # some of the pearsonr returns NaN when the variance is 0, so we fill with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def spearman_correlation_test(dataset, pvalue_threshold=0.05):\n",
    "    \"\"\"Same as correlation2 but with significance tests (pvalue <= pvalue_threshold)\n",
    "    \"\"\"\n",
    "    variables = dataset.columns # .drop([\"X\", \"Y\"])\n",
    "    corr_pvalue = pd.DataFrame(\n",
    "        # index=pd.MultiIndex.from_tuples(list(combinations(variables, 2))),\n",
    "        index=pd.MultiIndex.from_tuples(product(variables, variables)),\n",
    "        columns=[\"correlation\", \"pvalue\"],\n",
    "    )\n",
    "    for variable1, variable2 in corr_pvalue.index:\n",
    "        corr_pvalue.loc[(variable1, variable2), \"correlation\"], corr_pvalue.loc[(variable1, variable2), \"pvalue\"] = spearmanr(dataset[variable1], dataset[variable2])\n",
    "\n",
    "    correlations = corr_pvalue.reset_index().pivot(index=\"level_0\", columns=\"level_1\", values=\"correlation\")\n",
    "    pvalues_test = (corr_pvalue.reset_index().pivot(index=\"level_0\", columns=\"level_1\", values=\"pvalue\") <= pvalue_threshold).astype(float)\n",
    "\n",
    "    df = []\n",
    "    for variable in variables.drop([\"X\", \"Y\"]):\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"spearman(v,X)\": correlations.loc[variable, \"X\"],\n",
    "            f\"pvalue(spearman(v,X))<={pvalue_threshold}\": pvalues_test.loc[variable, \"X\"],\n",
    "            \"spearman(v,Y)\": correlations.loc[variable, \"Y\"],\n",
    "            f\"pvalue(spearman(v,Y))<={pvalue_threshold}\": pvalues_test.loc[variable, \"Y\"],\n",
    "            \"max(spearman(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().max(),\n",
    "            \"min(spearman(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().min(),\n",
    "            \"mean(spearman(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().mean(),\n",
    "            \"std(spearman(v, others))\": correlations.drop([variable], axis=\"columns\").loc[variable].abs().std(),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"spearman(X,Y)\"] = correlations.loc[\"X\", \"Y\"]\n",
    "    df[f\"pvalue(spearman(X,Y))<={pvalue_threshold}\"] = pvalues_test.loc[\"X\", \"Y\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def mutual_information(dataset):\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        tmp = mutual_info_regression(dataset.drop([variable], axis=\"columns\"), dataset[variable])\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"MI(v,X)\": mutual_info_regression(dataset[[variable]], dataset[\"X\"], discrete_features=False)[0],\n",
    "            \"MI(v,Y)\": mutual_info_regression(dataset[[variable]], dataset[\"Y\"], discrete_features=False)[0],\n",
    "            \"max(MI(v, others))\": tmp.max(),\n",
    "            \"min(MI(v, others))\": tmp.min(),\n",
    "            \"mean(MI(v, others))\": tmp.mean(),\n",
    "            \"std(MI(v, others))\": tmp.std(),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"MI(X,Y)\"] = mutual_info_regression(dataset[[\"X\"]], dataset[\"Y\"], discrete_features=False)[0]\n",
    "    return df\n",
    "\n",
    "\n",
    "def distance_correlation_features(dataset):\n",
    "    \"\"\"distance correlation between each variable and X, Y, [X,Y], and the\n",
    "    rest of the variables.\n",
    "    \"\"\"\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"dcor(v,X)\": distance_correlation(dataset[[variable]], dataset[\"X\"]),\n",
    "            \"dcor(v,Y)\": distance_correlation(dataset[[variable]], dataset[\"Y\"]),\n",
    "            \"dcor(v,[X,Y])\": distance_correlation(dataset[[variable]], dataset[[\"X\",\"Y\"]]),\n",
    "            \"dcor(v,not([v,X,Y]))\": distance_correlation(dataset[[variable]], dataset.drop([variable, \"X\",\"Y\"], axis=\"columns\")),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    df[\"dcor(X,Y)\"] = distance_correlation(dataset[\"X\"], dataset[\"Y\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def energy_distance_test(dataset, pvalue_threshold=0.05):\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        energy_test_vX = energy_test(dataset[[variable]], dataset[\"X\"])\n",
    "        energy_test_vY = energy_test(dataset[[variable]], dataset[\"Y\"])\n",
    "        d = {\n",
    "            \"variable\": variable,\n",
    "            \"energy_test(v,X))\": energy_test_vX.statistic,\n",
    "            f\"pvalue(energy_test(v,X))<={pvalue_threshold}\": (energy_test_vX.pvalue <= pvalue_threshold).astype(float),\n",
    "            \"energy_test(v,Y))\": energy_test_vY.statistic,\n",
    "            f\"pvalue(energy_test(v,Y))<={pvalue_threshold}\": (energy_test_vY.pvalue <= pvalue_threshold).astype(float),\n",
    "        }\n",
    "        df.append(d)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    energy_test_XY = energy_test(dataset[[\"X\"]], dataset[\"Y\"])\n",
    "    df[\"energy_test(X,Y)\"] = energy_test_XY.statistic\n",
    "    df[f\"pvalue(energy_test(X,Y))<={pvalue_threshold}\"] = (energy_test_XY.pvalue <= pvalue_threshold).astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "def label(adjacency_matrix):\n",
    "    labels = get_labels(adjacency_matrix)\n",
    "    variables = adjacency_matrix.columns.drop([\"X\", \"Y\"])\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"variable\": variables,\n",
    "            \"label\": [labels[variable] for variable in variables],\n",
    "        }\n",
    "    )\n",
    "    df[\"dataset\"] = adjacency_matrix.name\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_some_columns(filenames, function):\n",
    "    df = []\n",
    "    for filename in tqdm(filenames):\n",
    "        dataset_number = int(basename(filename).split(\".\")[0])\n",
    "        dataset = pd.read_csv(filename, index_col=0 if function == label else None)  # hack to have index_col=0 for label\n",
    "        dataset.name = dataset_number\n",
    "        df_dataset = function(dataset)\n",
    "        df_dataset[\"dataset\"] = dataset_number\n",
    "        df.append(df_dataset)\n",
    "\n",
    "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_some_columns_parallel(filenames, function, n_jobs=-1):\n",
    "    def f(filename, function):\n",
    "        dataset_number = int(basename(filename).split(\".\")[0])\n",
    "        dataset = pd.read_csv(filename, index_col=0 if function == label else None)  # hack to have index_col=0 for label\n",
    "        dataset.name = dataset_number\n",
    "        df_dataset = function(dataset)\n",
    "        df_dataset[\"dataset\"] = dataset_number\n",
    "        return df_dataset\n",
    "\n",
    "    df = Parallel(n_jobs=n_jobs)(delayed(f)(filename, function) for filename in tqdm(filenames))\n",
    "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_all_columns(functions_filenames, n_jobs=-1):\n",
    "    columns = []\n",
    "    for function, filenames in functions_filenames.items():\n",
    "        print(f\"set: {function.__name__}\")\n",
    "        feature_set = create_some_columns_parallel(filenames, function, n_jobs=n_jobs)\n",
    "        columns.append(feature_set)\n",
    "\n",
    "    # Merge all feature sets into a single dataframe:\n",
    "    columns = reduce(\n",
    "        lambda left, right: pd.merge(\n",
    "            left, right, on=[\"dataset\", \"variable\"]\n",
    "        ),\n",
    "        columns,\n",
    "    )\n",
    "    return columns\n",
    "\n",
    "\n",
    "def create_submission(X_test, filename=\"submission.csv\"):\n",
    "    submission_file = {}\n",
    "    for name, group in tqdm(X_test.groupby(\"dataset\")):\n",
    "        variables_labels = group[[\"variable\", \"label_predicted\"]].set_index(\"variable\")\n",
    "        variables = variables_labels.index.tolist()\n",
    "        variables_all = [\"X\", \"Y\"] + variables\n",
    "        adjacency_matrix = pd.DataFrame(index=variables_all, columns=variables_all)\n",
    "        adjacency_matrix.index.name = \"parent\"\n",
    "        adjacency_matrix[:] = 0\n",
    "        adjacency_matrix.loc[\"X\", \"Y\"] = 1\n",
    "        for v in variables:\n",
    "            l = variables_labels.loc[v].item()\n",
    "            if l == \"Cause of X\":\n",
    "                adjacency_matrix.loc[v, \"X\"] = 1\n",
    "            elif l == \"Cause of Y\":\n",
    "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
    "            elif l == \"Consequence of X\":\n",
    "                adjacency_matrix.loc[\"X\", v] = 1\n",
    "            elif l == \"Consequence of Y\":\n",
    "                adjacency_matrix.loc[\"Y\", v] = 1\n",
    "            elif l == \"Confounder\":\n",
    "                adjacency_matrix.loc[v, \"X\"] = 1\n",
    "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
    "            elif l == \"Collider\":\n",
    "                adjacency_matrix.loc[\"X\", v] = 1\n",
    "                adjacency_matrix.loc[\"Y\", v] = 1\n",
    "            elif l == \"Mediator\":\n",
    "                adjacency_matrix.loc[\"X\", v] = 1\n",
    "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
    "            elif l == \"Confounder\":\n",
    "                pass\n",
    "\n",
    "        for i in variables_all:\n",
    "            for j in variables_all:\n",
    "                submission_file[f'{name:05d}_{i}_{j}'] = int(adjacency_matrix.loc[i,j])\n",
    "\n",
    "    submission_file = pd.Series(submission_file)\n",
    "    submission_file = submission_file.reset_index()\n",
    "    submission_file.columns = ['example_id', 'prediction']\n",
    "    print(f\"Saving submission to {filename}\")\n",
    "    submission_file.to_csv(filename, index=False)\n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fd62a",
   "metadata": {},
   "source": [
    "### Preprocessing and feature extraction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e06424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for pickle files\n",
    "data_paths = {\n",
    "    'X_train': './data/X_train.pickle',\n",
    "    'y_train': './data/y_train.pickle',\n",
    "    'X_test': './data/X_test.pickle'\n",
    "}\n",
    "\n",
    "# Define the output directories for CSV files\n",
    "output_dirs = {\n",
    "    'X_train': './data/train/X/',\n",
    "    'y_train': './data/train/y/',\n",
    "    'X_test': './data/test/X/'\n",
    "}\n",
    "\n",
    "# Function to create directories if they do not exist\n",
    "def create_output_directories(output_dirs):\n",
    "    for dir_path in output_dirs.values():\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "        else:\n",
    "            print(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Create the output directories\n",
    "create_output_directories(output_dirs)\n",
    "\n",
    "\n",
    "# Process each pickle file\n",
    "for key, pickle_path in data_paths.items():\n",
    "    # Load the pickle file\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        data_dict = pickle.load(file)\n",
    "\n",
    "    # Save each DataFrame in the dictionary to a CSV file\n",
    "    for sub_key, df in data_dict.items():\n",
    "        output_dir = output_dirs[key]\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "        csv_path = Path(output_dir) / f'{sub_key}.csv'\n",
    "        df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70fbadb3-1e1a-4845-be20-cdbec2a60905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving filenames\n",
      "Creating Xy from 114 datasets\n",
      "set: ttest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:01<00:00, 61.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: pearson_correlation_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 202.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: mutual_information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:03<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: distance_correlation_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 33/114 [01:17<03:06,  2.31s/it]/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 114/114 [02:42<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: energy_distance_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:05<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 601.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding numeric labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>variable</th>\n",
       "      <th>ttest(v,X)</th>\n",
       "      <th>pvalue(ttest(v,X))&lt;=0.05</th>\n",
       "      <th>ttest(v,Y)</th>\n",
       "      <th>pvalue(ttest(v,Y))&lt;=0.05</th>\n",
       "      <th>ttest(X,Y)</th>\n",
       "      <th>pvalue(ttest(X,Y))&lt;=0.05</th>\n",
       "      <th>pearson(v,X)</th>\n",
       "      <th>pvalue(pearson(v,X))&lt;=0.05</th>\n",
       "      <th>...</th>\n",
       "      <th>dcor(v,not([v,X,Y]))</th>\n",
       "      <th>dcor(X,Y)</th>\n",
       "      <th>energy_test(v,X))</th>\n",
       "      <th>pvalue(energy_test(v,X))&lt;=0.05</th>\n",
       "      <th>energy_test(v,Y))</th>\n",
       "      <th>pvalue(energy_test(v,Y))&lt;=0.05</th>\n",
       "      <th>energy_test(X,Y)</th>\n",
       "      <th>pvalue(energy_test(X,Y))&lt;=0.05</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.986131e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.006382e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.917882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.872689</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cause of X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9.936606e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.137520e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.006382e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.915585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.872689</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Collider</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.270930e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.676273e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543819</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.584965e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.750369e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359845</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2.926888e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.687996e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205578</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cause of X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>406</td>\n",
       "      <td>7</td>\n",
       "      <td>2.140600e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.100344e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.994522e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971216</td>\n",
       "      <td>0.878168</td>\n",
       "      <td>-3.330669e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consequence of X</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.139994e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.002144e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414781</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.885781e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Confounder</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.958868e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.166739e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564421</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>3.330669e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mediator</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.526721e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.281781e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.185013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223753</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>409</td>\n",
       "      <td>3</td>\n",
       "      <td>8.315744e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.470604e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.538501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505062</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consequence of X</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset variable    ttest(v,X)  pvalue(ttest(v,X))<=0.05    ttest(v,Y)  \\\n",
       "0          3        2 -1.986131e-16                       0.0  0.000000e+00   \n",
       "1          3        3  9.936606e-17                       0.0  1.137520e-16   \n",
       "2         10        0 -3.270930e-17                       0.0  9.676273e-17   \n",
       "3         10        1 -4.584965e-17                       0.0  1.750369e-16   \n",
       "4         10        3  2.926888e-17                       0.0  6.687996e-17   \n",
       "..       ...      ...           ...                       ...           ...   \n",
       "713      406        7  2.140600e-16                       0.0  2.100344e-16   \n",
       "714      409        0 -2.139994e-16                       0.0 -3.002144e-16   \n",
       "715      409        1 -2.958868e-17                       0.0 -1.166739e-16   \n",
       "716      409        2 -2.526721e-16                       0.0 -1.281781e-16   \n",
       "717      409        3  8.315744e-17                       0.0 -2.470604e-16   \n",
       "\n",
       "     pvalue(ttest(v,Y))<=0.05    ttest(X,Y)  pvalue(ttest(X,Y))<=0.05  \\\n",
       "0                         0.0 -3.006382e-16                       0.0   \n",
       "1                         0.0 -3.006382e-16                       0.0   \n",
       "2                         0.0  3.437833e-17                       0.0   \n",
       "3                         0.0  3.437833e-17                       0.0   \n",
       "4                         0.0  3.437833e-17                       0.0   \n",
       "..                        ...           ...                       ...   \n",
       "713                       0.0  1.994522e-16                       0.0   \n",
       "714                       0.0  1.780548e-16                       0.0   \n",
       "715                       0.0  1.780548e-16                       0.0   \n",
       "716                       0.0  1.780548e-16                       0.0   \n",
       "717                       0.0  1.780548e-16                       0.0   \n",
       "\n",
       "     pearson(v,X)  pvalue(pearson(v,X))<=0.05  ...  dcor(v,not([v,X,Y]))  \\\n",
       "0       -0.917882                         1.0  ...              0.852501   \n",
       "1       -0.915585                         1.0  ...              0.852501   \n",
       "2       -0.104880                         1.0  ...              0.543819   \n",
       "3        0.121371                         1.0  ...              0.359845   \n",
       "4       -0.379893                         1.0  ...              0.205578   \n",
       "..            ...                         ...  ...                   ...   \n",
       "713      0.896808                         1.0  ...              0.971216   \n",
       "714      0.586998                         1.0  ...              0.414781   \n",
       "715      0.662444                         1.0  ...              0.564421   \n",
       "716     -0.185013                         1.0  ...              0.223753   \n",
       "717     -0.538501                         1.0  ...              0.505062   \n",
       "\n",
       "     dcor(X,Y)  energy_test(v,X))  pvalue(energy_test(v,X))<=0.05  \\\n",
       "0     0.872689       1.665335e-13                             0.0   \n",
       "1     0.872689       2.220446e-13                             0.0   \n",
       "2     0.095028       0.000000e+00                             0.0   \n",
       "3     0.095028       5.551115e-14                             0.0   \n",
       "4     0.095028      -1.110223e-13                             0.0   \n",
       "..         ...                ...                             ...   \n",
       "713   0.878168      -3.330669e-13                             0.0   \n",
       "714   0.739884       1.665335e-13                             0.0   \n",
       "715   0.739884       3.330669e-13                             0.0   \n",
       "716   0.739884       1.110223e-13                             0.0   \n",
       "717   0.739884       1.665335e-13                             0.0   \n",
       "\n",
       "     energy_test(v,Y))  pvalue(energy_test(v,Y))<=0.05  energy_test(X,Y)  \\\n",
       "0        -1.665335e-13                             0.0     -1.110223e-13   \n",
       "1         1.110223e-13                             0.0     -1.110223e-13   \n",
       "2        -5.551115e-14                             0.0     -1.665335e-13   \n",
       "3        -1.110223e-13                             0.0     -1.665335e-13   \n",
       "4         5.551115e-14                             0.0     -1.665335e-13   \n",
       "..                 ...                             ...               ...   \n",
       "713      -1.665335e-13                             0.0     -1.665335e-13   \n",
       "714      -3.885781e-13                             0.0      2.220446e-13   \n",
       "715       0.000000e+00                             0.0      2.220446e-13   \n",
       "716       0.000000e+00                             0.0      2.220446e-13   \n",
       "717       1.665335e-13                             0.0      2.220446e-13   \n",
       "\n",
       "     pvalue(energy_test(X,Y))<=0.05             label  y  \n",
       "0                               0.0        Cause of X  0  \n",
       "1                               0.0          Collider  2  \n",
       "2                               0.0        Cause of Y  1  \n",
       "3                               0.0        Cause of Y  1  \n",
       "4                               0.0        Cause of X  0  \n",
       "..                              ...               ... ..  \n",
       "713                             0.0  Consequence of X  4  \n",
       "714                             0.0        Confounder  3  \n",
       "715                             0.0          Mediator  7  \n",
       "716                             0.0       Independent  6  \n",
       "717                             0.0  Consequence of X  4  \n",
       "\n",
       "[718 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadir = Path(\"train\")\n",
    "print(\"Retrieving filenames\")\n",
    "filenames_X = sorted(glob(str(datadir / \"X\" / \"*.csv\")))\n",
    "filenames_y = sorted(glob(str(datadir / \"y\" / \"*.csv\")))\n",
    "\n",
    "print(f\"Creating Xy from {len(filenames_X)} datasets\")\n",
    "Xy = create_all_columns(\n",
    "    {\n",
    "        ttest: filenames_X,\n",
    "        pearson_correlation_test: filenames_X,\n",
    "        mutual_information: filenames_X,\n",
    "        distance_correlation_features: filenames_X,\n",
    "        energy_distance_test: filenames_X,\n",
    "        label: filenames_y\n",
    "    }\n",
    ")\n",
    "print(\"Adding numeric labels\")\n",
    "le = LabelEncoder()\n",
    "Xy[\"y\"] = le.fit_transform(Xy[\"label\"])\n",
    "# reordering columns:\n",
    "Xy = Xy[[\"dataset\", \"variable\"] + Xy.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "display(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0d8c1-890e-45a2-a4e7-f0e7dc5c7874",
   "metadata": {},
   "source": [
    "### Extracting `X`, `y`, and grouping\n",
    "\n",
    "Groups are essentials for cross-validation because we do not want variables of one dataset to be in the training set and other variables of the same dataset to be in the test set - because this would artifically inflate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c141b467-37ed-4bea-9c58-fbefb9eab6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting X, y, and group\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttest(v,X)</th>\n",
       "      <th>pvalue(ttest(v,X))&lt;=0.05</th>\n",
       "      <th>ttest(v,Y)</th>\n",
       "      <th>pvalue(ttest(v,Y))&lt;=0.05</th>\n",
       "      <th>ttest(X,Y)</th>\n",
       "      <th>pvalue(ttest(X,Y))&lt;=0.05</th>\n",
       "      <th>pearson(v,X)</th>\n",
       "      <th>pvalue(pearson(v,X))&lt;=0.05</th>\n",
       "      <th>pearson(v,Y)</th>\n",
       "      <th>pvalue(pearson(v,Y))&lt;=0.05</th>\n",
       "      <th>...</th>\n",
       "      <th>dcor(v,Y)</th>\n",
       "      <th>dcor(v,[X,Y])</th>\n",
       "      <th>dcor(v,not([v,X,Y]))</th>\n",
       "      <th>dcor(X,Y)</th>\n",
       "      <th>energy_test(v,X))</th>\n",
       "      <th>pvalue(energy_test(v,X))&lt;=0.05</th>\n",
       "      <th>energy_test(v,Y))</th>\n",
       "      <th>pvalue(energy_test(v,Y))&lt;=0.05</th>\n",
       "      <th>energy_test(X,Y)</th>\n",
       "      <th>pvalue(energy_test(X,Y))&lt;=0.05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.986131e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.006382e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.917882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810337</td>\n",
       "      <td>0.910528</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.872689</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.936606e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.137520e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.006382e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.915585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975479</td>\n",
       "      <td>0.974374</td>\n",
       "      <td>0.852501</td>\n",
       "      <td>0.872689</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.270930e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.676273e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.104880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.494988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529882</td>\n",
       "      <td>0.452116</td>\n",
       "      <td>0.543819</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.584965e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.750369e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132359</td>\n",
       "      <td>0.141118</td>\n",
       "      <td>0.359845</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.926888e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.687996e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.437833e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.379893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.057123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>0.471113</td>\n",
       "      <td>0.205578</td>\n",
       "      <td>0.095028</td>\n",
       "      <td>-1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.551115e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>2.140600e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.100344e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.994522e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892603</td>\n",
       "      <td>0.920827</td>\n",
       "      <td>0.971216</td>\n",
       "      <td>0.878168</td>\n",
       "      <td>-3.330669e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>-2.139994e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.002144e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525221</td>\n",
       "      <td>0.602685</td>\n",
       "      <td>0.414781</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.885781e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>-2.958868e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.166739e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777567</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.564421</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>3.330669e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>-2.526721e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.281781e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.185013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.151198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141962</td>\n",
       "      <td>0.169959</td>\n",
       "      <td>0.223753</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.110223e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>8.315744e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.470604e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780548e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.538501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.568687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546949</td>\n",
       "      <td>0.572296</td>\n",
       "      <td>0.505062</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.665335e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.220446e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ttest(v,X)  pvalue(ttest(v,X))<=0.05    ttest(v,Y)  \\\n",
       "0   -1.986131e-16                       0.0  0.000000e+00   \n",
       "1    9.936606e-17                       0.0  1.137520e-16   \n",
       "2   -3.270930e-17                       0.0  9.676273e-17   \n",
       "3   -4.584965e-17                       0.0  1.750369e-16   \n",
       "4    2.926888e-17                       0.0  6.687996e-17   \n",
       "..            ...                       ...           ...   \n",
       "713  2.140600e-16                       0.0  2.100344e-16   \n",
       "714 -2.139994e-16                       0.0 -3.002144e-16   \n",
       "715 -2.958868e-17                       0.0 -1.166739e-16   \n",
       "716 -2.526721e-16                       0.0 -1.281781e-16   \n",
       "717  8.315744e-17                       0.0 -2.470604e-16   \n",
       "\n",
       "     pvalue(ttest(v,Y))<=0.05    ttest(X,Y)  pvalue(ttest(X,Y))<=0.05  \\\n",
       "0                         0.0 -3.006382e-16                       0.0   \n",
       "1                         0.0 -3.006382e-16                       0.0   \n",
       "2                         0.0  3.437833e-17                       0.0   \n",
       "3                         0.0  3.437833e-17                       0.0   \n",
       "4                         0.0  3.437833e-17                       0.0   \n",
       "..                        ...           ...                       ...   \n",
       "713                       0.0  1.994522e-16                       0.0   \n",
       "714                       0.0  1.780548e-16                       0.0   \n",
       "715                       0.0  1.780548e-16                       0.0   \n",
       "716                       0.0  1.780548e-16                       0.0   \n",
       "717                       0.0  1.780548e-16                       0.0   \n",
       "\n",
       "     pearson(v,X)  pvalue(pearson(v,X))<=0.05  pearson(v,Y)  \\\n",
       "0       -0.917882                         1.0      0.792132   \n",
       "1       -0.915585                         1.0      0.977161   \n",
       "2       -0.104880                         1.0      0.494988   \n",
       "3        0.121371                         1.0      0.035420   \n",
       "4       -0.379893                         1.0     -0.057123   \n",
       "..            ...                         ...           ...   \n",
       "713      0.896808                         1.0      0.892814   \n",
       "714      0.586998                         1.0      0.527831   \n",
       "715      0.662444                         1.0      0.804614   \n",
       "716     -0.185013                         1.0     -0.151198   \n",
       "717     -0.538501                         1.0     -0.568687   \n",
       "\n",
       "     pvalue(pearson(v,Y))<=0.05  ...  dcor(v,Y)  dcor(v,[X,Y])  \\\n",
       "0                           1.0  ...   0.810337       0.910528   \n",
       "1                           1.0  ...   0.975479       0.974374   \n",
       "2                           1.0  ...   0.529882       0.452116   \n",
       "3                           0.0  ...   0.132359       0.141118   \n",
       "4                           0.0  ...   0.079846       0.471113   \n",
       "..                          ...  ...        ...            ...   \n",
       "713                         1.0  ...   0.892603       0.920827   \n",
       "714                         1.0  ...   0.525221       0.602685   \n",
       "715                         1.0  ...   0.777567       0.754745   \n",
       "716                         1.0  ...   0.141962       0.169959   \n",
       "717                         1.0  ...   0.546949       0.572296   \n",
       "\n",
       "     dcor(v,not([v,X,Y]))  dcor(X,Y)  energy_test(v,X))  \\\n",
       "0                0.852501   0.872689       1.665335e-13   \n",
       "1                0.852501   0.872689       2.220446e-13   \n",
       "2                0.543819   0.095028       0.000000e+00   \n",
       "3                0.359845   0.095028       5.551115e-14   \n",
       "4                0.205578   0.095028      -1.110223e-13   \n",
       "..                    ...        ...                ...   \n",
       "713              0.971216   0.878168      -3.330669e-13   \n",
       "714              0.414781   0.739884       1.665335e-13   \n",
       "715              0.564421   0.739884       3.330669e-13   \n",
       "716              0.223753   0.739884       1.110223e-13   \n",
       "717              0.505062   0.739884       1.665335e-13   \n",
       "\n",
       "     pvalue(energy_test(v,X))<=0.05  energy_test(v,Y))  \\\n",
       "0                               0.0      -1.665335e-13   \n",
       "1                               0.0       1.110223e-13   \n",
       "2                               0.0      -5.551115e-14   \n",
       "3                               0.0      -1.110223e-13   \n",
       "4                               0.0       5.551115e-14   \n",
       "..                              ...                ...   \n",
       "713                             0.0      -1.665335e-13   \n",
       "714                             0.0      -3.885781e-13   \n",
       "715                             0.0       0.000000e+00   \n",
       "716                             0.0       0.000000e+00   \n",
       "717                             0.0       1.665335e-13   \n",
       "\n",
       "     pvalue(energy_test(v,Y))<=0.05  energy_test(X,Y)  \\\n",
       "0                               0.0     -1.110223e-13   \n",
       "1                               0.0     -1.110223e-13   \n",
       "2                               0.0     -1.665335e-13   \n",
       "3                               0.0     -1.665335e-13   \n",
       "4                               0.0     -1.665335e-13   \n",
       "..                              ...               ...   \n",
       "713                             0.0     -1.665335e-13   \n",
       "714                             0.0      2.220446e-13   \n",
       "715                             0.0      2.220446e-13   \n",
       "716                             0.0      2.220446e-13   \n",
       "717                             0.0      2.220446e-13   \n",
       "\n",
       "     pvalue(energy_test(X,Y))<=0.05  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "..                              ...  \n",
       "713                             0.0  \n",
       "714                             0.0  \n",
       "715                             0.0  \n",
       "716                             0.0  \n",
       "717                             0.0  \n",
       "\n",
       "[718 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      2\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "713    4\n",
       "714    3\n",
       "715    7\n",
       "716    6\n",
       "717    4\n",
       "Name: y, Length: 718, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        3\n",
       "2       10\n",
       "3       10\n",
       "4       10\n",
       "      ... \n",
       "713    406\n",
       "714    409\n",
       "715    409\n",
       "716    409\n",
       "717    409\n",
       "Name: dataset, Length: 718, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Extracting X, y, and group\")\n",
    "X = Xy.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = Xy[\"y\"]\n",
    "group = Xy[\"dataset\"]\n",
    "display(X)\n",
    "display(y)\n",
    "display(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a1f9d-2ca4-4a70-944c-a5f05a9e23b0",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The `train` function trains, evaluates, and saves a list of machine learning models using cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c10ff7-5f46-4340-80e3-b4e5a9ffde0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('ridgeclassifiercv',\n",
      "                 RidgeClassifierCV(class_weight='balanced'))]): mean balanced accuracy = 0.2708\n",
      "Model saved to models/Pipeline.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=3, n_jobs=-1): mean balanced accuracy = 0.2931\n",
      "Model saved to models/RandomForestClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=5, n_jobs=-1): mean balanced accuracy = 0.2949\n",
      "Model saved to models/RandomForestClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=7, n_jobs=-1): mean balanced accuracy = 0.3238\n",
      "Model saved to models/RandomForestClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=11, n_jobs=-1): mean balanced accuracy = 0.2785\n",
      "Model saved to models/RandomForestClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=13, n_jobs=-1): mean balanced accuracy = 0.2673\n",
      "Model saved to models/RandomForestClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', n_jobs=-1): mean balanced accuracy = 0.2458\n",
      "Model saved to models/RandomForestClassifier.joblib\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=3): mean balanced accuracy = 0.2632\n",
      "Model saved to models/DecisionTreeClassifier.joblib\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=5): mean balanced accuracy = 0.2987\n",
      "Model saved to models/DecisionTreeClassifier.joblib\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=7): mean balanced accuracy = 0.2964\n",
      "Model saved to models/DecisionTreeClassifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n",
      "/home/skhotijah/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:848: UserWarning: The groups parameter is ignored by StratifiedKFold\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', max_depth=11): mean balanced accuracy = 0.2588\n",
      "Model saved to models/DecisionTreeClassifier.joblib\n"
     ]
    }
   ],
   "source": [
    "def train(models, X, y, groups=None, model_directory_path=\"models\"):\n",
    "    \"\"\"\n",
    "    Train, evaluate, and save a list of models using cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - models: List of models to be evaluated.\n",
    "    - X: Feature matrix.\n",
    "    - y: Target vector.\n",
    "    - groups: Optional array of group labels for group-based cross-validation.\n",
    "    - model_directory_path: Directory where the models will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_directory_path):\n",
    "        os.makedirs(model_directory_path)\n",
    "\n",
    "    for model in models:\n",
    "        # Fit the model on the entire dataset\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        results = cross_val_score(model, X, y, groups=groups, verbose=True, scoring=\"balanced_accuracy\")\n",
    "        print(f\"{model}: mean balanced accuracy = {results.mean():.4f}\")\n",
    "\n",
    "        # Save the model\n",
    "        model_name = type(model).__name__  # Get the name of the model class\n",
    "        model_file_path = os.path.join(model_directory_path, f\"{model_name}.joblib\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "        print(f\"Model saved to {model_file_path}\")\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    make_pipeline(StandardScaler(), RidgeClassifierCV(class_weight=\"balanced\")),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=3, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=7, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=11, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=13, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    DecisionTreeClassifier(class_weight=\"balanced\", max_depth=3),\n",
    "    DecisionTreeClassifier(class_weight=\"balanced\", max_depth=5),\n",
    "    DecisionTreeClassifier(class_weight=\"balanced\", max_depth=7),\n",
    "    DecisionTreeClassifier(class_weight=\"balanced\", max_depth=11),\n",
    "]\n",
    "\n",
    "train(models, X, y, groups=group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d3a4f-00af-4519-8686-e10f6b26c636",
   "metadata": {},
   "source": [
    "## Infer\n",
    "\n",
    "The infer function that will be called by the Crunch platform is defined below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a94df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model_directory_path=\"models\", X_test=None, le=None):\n",
    "    filenames_test_X = sorted(glob(str(Path(\"test\") / \"X\" / \"*.csv\")))\n",
    "    print(f\"Creating X_test from {len(filenames_test_X)} datasets\")\n",
    "    X_test = create_all_columns(\n",
    "        {\n",
    "            ttest: filenames_test_X,\n",
    "            pearson_correlation_test: filenames_test_X,\n",
    "            mutual_information: filenames_test_X,\n",
    "            distance_correlation_features: filenames_test_X,\n",
    "            energy_distance_test: filenames_test_X,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    Load models from the specified directory and make predictions on the test data.\n",
    "\n",
    "    Parameters:\n",
    "    - model_directory_path: Directory where the models are saved.\n",
    "    - X_test: DataFrame of test features.\n",
    "    - le: LabelEncoder instance used for transforming labels.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: Dictionary with model names as keys and predictions as values.\n",
    "    - X_test: DataFrame with predictions as new columns.\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    # Check if the model directory exists\n",
    "    if not os.path.exists(model_directory_path):\n",
    "        raise FileNotFoundError(f\"Model directory {model_directory_path} does not exist.\")\n",
    "    \n",
    "    # Get a list of all model files in the directory\n",
    "    model_files = [f for f in os.listdir(model_directory_path) if f.endswith(\".joblib\")]\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        # Load the model\n",
    "        model_name = os.path.splitext(model_file)[0]\n",
    "        model_path = os.path.join(model_directory_path, model_file)\n",
    "        \n",
    "        try:\n",
    "            model = joblib.load(model_path)\n",
    "            \n",
    "            # Make predictions\n",
    "            if X_test is not None:\n",
    "                X_test_features = X_test.drop([\"dataset\", \"variable\"], axis=\"columns\", errors='ignore')\n",
    "                try:\n",
    "                    y_predicted = model.predict(X_test_features)\n",
    "                    predictions[model_name] = y_predicted\n",
    "                    \n",
    "                    # Add predictions to X_test\n",
    "                    X_test[f\"y_predicted\"] = y_predicted\n",
    "                    \n",
    "                    if le is not None:\n",
    "                        X_test[f\"label_predicted\"] = le.inverse_transform(y_predicted)\n",
    "                    else:\n",
    "                        print(\"LabelEncoder instance is not provided. Predictions will not be inverse-transformed.\")\n",
    "                        \n",
    "                except NotFittedError:\n",
    "                    print(f\"Model {model_name} is not fitted.\")\n",
    "                    predictions[model_name] = None\n",
    "            else:\n",
    "                raise ValueError(\"X_test must be provided for predictions.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with model {model_name}: {e}\")\n",
    "            predictions[model_name] = None\n",
    "    \n",
    "    # Display the updated DataFrame\n",
    "    print(X_test.head())\n",
    "    \n",
    "    return predictions, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c69bf-2c13-4fa6-841b-886a4e087a04",
   "metadata": {},
   "source": [
    "## Creating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "469abfb7-c118-4f40-8209-1502ca0881e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 391.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to supervised_baseline.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "submission = create_submission(X_test, filename=\"supervised_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb2826",
   "metadata": {},
   "source": [
    "## Test your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b0fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crunch.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
