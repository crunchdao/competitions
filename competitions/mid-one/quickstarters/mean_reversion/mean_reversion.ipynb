{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/mid-one/quickstarters/mean_reversion/mean_reversion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/mid-one/assets/banner.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpCh-JZToCzK"
   },
   "source": [
    "# Mean Reversion\n",
    "\n",
    "## How is it different to a forecast?\n",
    "\n",
    "This notebook tries to predict whether a time-series will go up or down on average - though only when it has a strong opinion. To be precise, our attacker will consume a univariate sequence of numerical data points $x_1, x_2, \\dots x_t$ and try to exploit deviations from the [martingale property](https://en.wikipedia.org/wiki/Martingale_(probability_theory)), which is to say that we expect the series $x_t$ to satisfy:\n",
    "\n",
    "$$ E[x_{t+k}] \\approx x_t $$\n",
    "\n",
    "roughly. Of course, there's no such thing in this world as a perfect martingale and it is your job to indicate when\n",
    "\n",
    "$$ E[x_{t+k}] > x_t + \\epsilon $$\n",
    "\n",
    "by returning a positive value, or conversely. Here $\\epsilon$ finds interpretation as a trading cost. The attacker will *typically* return `0` meaning that it thinks:\n",
    "\n",
    "$$  x_t - \\epsilon   > E[x_{t+k}] > x_t + \\epsilon $$\n",
    "\n",
    "because trading opportunities are probably on the rare side - though obviously this is problem dependent. The $\\epsilon$ and $k$ (`horizon`) parameters are set [here](https://github.com/microprediction/midone/blob/main/midone/gameconfig.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new token here: https://hub.crunchdao.com/competitions/mid-one/submit/via/notebook\n",
    "\n",
    "%pip install --upgrade crunch-cli\n",
    "!crunch setup --notebook mid-one hello --token aaaabbbbccccddddeeeeffff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7qxqYHfMqvQ4"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "import typing\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crunch\n",
    "\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = crunch.load_streams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training stream: {len(x_train)}\")\n",
    "\n",
    "average_length = statistics.mean(len(stream) for stream in x_train)\n",
    "print(f\"Average length of training streams: {average_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(stream):\n",
    "    pandas.Series((\n",
    "        message[\"x\"]\n",
    "        for message in stream\n",
    "    )).plot()\n",
    "\n",
    "plot(x_train[0])\n",
    "plot(x_train[1])\n",
    "plot(x_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrunchDAO Code Interface\n",
    "\n",
    "[Submitting to the CrunchDAO platform requires 2 functions, `train` and `infer`.](https://docs.crunchdao.com/competitions/code-interface) Any line that is not in a function or is not an import will be commented when the notebook is processed.\n",
    "\n",
    "The content of the function is the same as the example, but the train must save the model to be read in infer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gu4daet75Fg"
   },
   "source": [
    "### The `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPMdvBBD76xG",
    "outputId": "8c1f01a6-52d7-4b86-e2ea-b972da576868"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    We do not recommend using the train function.\n",
    "    \n",
    "    Training should be done before running anything in the cloud environment.\n",
    "    \"\"\"\n",
    "\n",
    "    pass  # no training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCwBbf2XANK9"
   },
   "source": [
    "## The `infer` function\n",
    "\n",
    "Your notebook should have an infer function that can yield one prediction at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmdS8fkZfqnE",
    "outputId": "4236f589-04c3-4061-bfa7-79029258ec7f"
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    stream: typing.Iterator[dict],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    # Initialize your parameters.\n",
    "    a = 0.15\n",
    "\n",
    "    # Initialize your state.\n",
    "    running_avg: float = None\n",
    "\n",
    "    # Signals to the system that your attacker is initialized and ready.\n",
    "    yield  # Leave this here.\n",
    "\n",
    "    for message in stream:\n",
    "        x = message[\"x\"]\n",
    "\n",
    "        # tick\n",
    "        if running_avg is None:\n",
    "            running_avg = x\n",
    "        else:\n",
    "            running_avg = (1 - a) * running_avg + a * x\n",
    "\n",
    "        # Be sure to yield, even if the decision is zero.\n",
    "        if x > running_avg + 2:\n",
    "            yield -1  # sell\n",
    "        elif x < running_avg - 2:\n",
    "            yield 1  # buy\n",
    "        else:\n",
    "            yield 0  # hold\n",
    "\n",
    "\n",
    "# A quick test that indicates how your infer function will be used when you upload this notebook:\n",
    "messages = [{'x': 2.0}] * 10\n",
    "for y in infer(messages, model_directory_path=\"resources/\"):\n",
    "    # the first value is `None`, this is intended\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = crunch.test()\n",
    "display(prediction)\n",
    "\n",
    "display(prediction[\"prediction\"].value_counts())\n",
    "\n",
    "print(\"Download this notebook and submit it to the platform: https://hub.crunchdao.com/competitions/mid-one/submit/via/notebook\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6keI5dhzzA91GFxncpHCk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
