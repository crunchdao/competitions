{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/mid-one/quickstarters/regression_attacker/regression_attacker.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/mid-one/assets/banner.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpCh-JZToCzK"
   },
   "source": [
    "# Regression Attacker\n",
    "\n",
    "This notebook demonstrates how to create an `Attacker` described in [attacker.md](https://github.com/microprediction/midone/blob/main/midone/attackers/attacker.md). You may want to glance at this [notebook](../mean_reversion_attacker/mean_reversion_attacker.ipynb) also, if you seek more context or wish to know how these attackers can be used in a new tournament.\n",
    "\n",
    "Here we'll use the river package to update a running regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade midone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new token here: https://hub.crunchdao.com/competitions/mid-one/submit/via/notebook\n",
    "\n",
    "%pip install --upgrade crunch-cli\n",
    "!crunch setup --notebook mid-one hello --token aaaabbbbccccddddeeeeffff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7qxqYHfMqvQ4"
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "import collections\n",
    "\n",
    "import pandas\n",
    "from midone import EPSILON, HORIZON, Attacker\n",
    "from midone.accounting.pnlutil import add_pnl_summaries, zero_pnl_summary\n",
    "from river import linear_model\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crunch\n",
    "\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4INVybLMsraQ"
   },
   "source": [
    "## Creating a Momentum based Attacker\n",
    "We derive from `Attacker` and use `linear_model.LinearRegression` from the river package to maintain a regression estimate of the value `HORIZON` steps ahead. Then, we `buy` if the prediction is considerably higher than `EPSILON` above the current value, and conversely.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cn_fMDz0ukgK"
   },
   "outputs": [],
   "source": [
    "class MyAttacker(Attacker):\n",
    "    \"\"\"\n",
    "    An attacker that uses an online linear regression model to predict future values\n",
    "    and make trading decisions based on the expected profit exceeding EPSILON.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_lags=5,\n",
    "        threshold=1.0,\n",
    "        burn_in=1000,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the attacker.\n",
    "\n",
    "        Parameters:\n",
    "        - num_lags (int): Number of lagged values to use as features.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_lags = num_lags\n",
    "        self.threshold = threshold\n",
    "        self.burn_in = burn_in\n",
    "\n",
    "        # Online linear regression model\n",
    "        self.model = linear_model.LinearRegression(\n",
    "            # Initialize intercept to 0\n",
    "            intercept_init=0.0,\n",
    "\n",
    "            # Freeze the intercept (no learning)\n",
    "            intercept_lr=0.0\n",
    "        )\n",
    "\n",
    "        # Queue to store input vectors and time indices\n",
    "        self.input_queue = collections.deque()\n",
    "        self.current_ndx = 0\n",
    "\n",
    "    def tick(self, x):\n",
    "        \"\"\"\n",
    "        Processes the new data point.\n",
    "\n",
    "        - Updates the time index.\n",
    "        - Maintains a queue of input vectors.\n",
    "        - When the future value arrives after HORIZON steps, updates the model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (float): The new data point.\n",
    "        \"\"\"\n",
    "        # The history is maintained by the parent class; no need to call tick_history()\n",
    "\n",
    "        self.current_ndx += 1\n",
    "        X_t = self.get_recent_history(n=self.num_lags)\n",
    "        if len(X_t) >= self.num_lags:\n",
    "            self.input_queue.append({\n",
    "                'ndx': self.current_ndx,\n",
    "                'X': X_t\n",
    "            })\n",
    "\n",
    "        # Check if we can update the model with data from HORIZON steps ago\n",
    "        while self.input_queue and self.input_queue[0]['ndx'] <= self.current_ndx - HORIZON:\n",
    "            # Retrieve the input vector and its time index\n",
    "            past_data = self.input_queue.popleft()\n",
    "            X_past = past_data['X']\n",
    "\n",
    "            # The target value y is the data point at time 'time_past + HORIZON'\n",
    "            # Since we're at 'current_time', and 'current_time = time_past + HORIZON', we can use 'x' as y\n",
    "            y = x  # Current data point is the target for the input from HORIZON steps ago\n",
    "\n",
    "            # Prepare the feature dictionary in the form demanded by river package\n",
    "            X_past_dict = {\n",
    "                f'lag_{i}': value\n",
    "                for i, value in enumerate(X_past)\n",
    "            }\n",
    "\n",
    "            # Update the model incrementally\n",
    "            self.model.learn_one(X_past_dict, y)\n",
    "\n",
    "    def predict(self, horizon=HORIZON):\n",
    "        \"\"\"\n",
    "        Makes a prediction for HORIZON steps ahead and decides whether to buy, sell, or hold.\n",
    "\n",
    "        Parameters:\n",
    "        - horizon (int): The prediction horizon (should be HORIZON).\n",
    "\n",
    "        Returns:\n",
    "        - int: 1 for buy, -1 for sell, 0 for hold.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.current_ndx < self.burn_in:\n",
    "            return 0   # Not enough data for model to be reliable\n",
    "\n",
    "        # Ensure we have enough history to make a prediction\n",
    "        if len(self.history) < self.num_lags:\n",
    "            return 0  # Not enough history to make a prediction\n",
    "\n",
    "        # Create the input vector using the most recent 'lag' values\n",
    "        X_t = list(self.history)[-self.num_lags:]\n",
    "        X_t_dict = {\n",
    "            f'lag_{i}': value\n",
    "            for i, value in enumerate(X_t)\n",
    "        }\n",
    "\n",
    "        # Predict the future value HORIZON steps ahead\n",
    "        y_pred = self.model.predict_one(X_t_dict)\n",
    "\n",
    "        # Get the last known value\n",
    "        last_value = X_t[-1]\n",
    "\n",
    "        # Calculate the expected profit\n",
    "        expected_profit = y_pred - last_value\n",
    "\n",
    "        # Decide based on whether expected profit exceeds a multiple of EPSILON\n",
    "        if expected_profit > self.threshold * EPSILON:\n",
    "            return 1  # Buy\n",
    "        elif expected_profit < -self.threshold * EPSILON:\n",
    "            return -1  # Sell\n",
    "        else:\n",
    "            return 0  # Hold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ68K8PCMAlo"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "### `tick` Method\n",
    "\n",
    "The `tick` method processes a new incoming data point and updates the attacker's state accordingly:\n",
    "\n",
    "- **Increment the Time Index**: The method updates `self.current_ndx` to track the current observation index.\n",
    "- **Maintain Input History**: It retrieves the recent history of `num_lags` values and appends the new input vector (`X_t`) to the `input_queue`, associating it with the current index.\n",
    "- **Update the Model**: The method checks if it has received enough future data (after `HORIZON` steps) to use an earlier input vector as a training example. If so, it pairs the input vector from `HORIZON` steps ago with the current data point `x` (used as the target value `y`) and incrementally updates the online regression model.\n",
    "\n",
    "### `predict` Method\n",
    "\n",
    "The `predict` method makes a decision based on the modelâ€™s prediction for the value `HORIZON` steps ahead:\n",
    "\n",
    "- **Burn-in Check**: If the number of processed data points is less than the `burn_in` threshold, the model refrains from making predictions.\n",
    "- **Prepare Input Features**: It checks if there's enough history to form an input vector of `num_lags` values. If there is, it prepares a dictionary of lagged values (`X_t_dict`) to be used by the model.\n",
    "- **Prediction**: The method predicts the next value `HORIZON` steps ahead using the online regression model.\n",
    "- **Decision Logic**: It calculates the expected profit by comparing the predicted future value with the last known value. If the expected profit exceeds a threshold (a multiple of `EPSILON`), it returns:\n",
    "  - `1` (buy) if the profit is positive,\n",
    "  - `-1` (sell) if the profit is negative,\n",
    "  - `0` (hold) if the profit is too small to act upon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh6jpef0vAjp"
   },
   "source": [
    "## Run the attacker on mock data\n",
    "We use `tick_and_predict` from the parent class as this will track profit and loss for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S0yzoHAOv9W4"
   },
   "outputs": [],
   "source": [
    "attacker = MyAttacker()  # Always reset an attacker\n",
    "\n",
    "data = [1, 3, 4, 2, 4, 5, 1, 5, 2, 5, 10] * 100\n",
    "for x in data:\n",
    "    y = attacker.tick_and_predict(x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTsfKoLo3lIT"
   },
   "source": [
    "## Run the attacker on real data\n",
    "We reset the attacker every time it encounters a new stream, but track aggregate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = crunch.load_streams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqfStlKN3m5s",
    "outputId": "dd965b3e-a7f6-4553-dda1-633d4277abde"
   },
   "outputs": [],
   "source": [
    "total_pnl = []\n",
    "\n",
    "for stream in tqdm(x_train):\n",
    "    attacker = MyAttacker(num_lags=2, threshold=2.0, burn_in=1000)\n",
    "    pnl = zero_pnl_summary()\n",
    "\n",
    "    for message in tqdm(stream, leave=False):\n",
    "        attacker.tick_and_predict(x=message['x'])\n",
    "\n",
    "    stream_pnl = attacker.pnl.summary()\n",
    "\n",
    "    pnl = add_pnl_summaries(pnl, stream_pnl)\n",
    "    if pnl['num_resolved_decisions'] > 0:\n",
    "        pnl.update({\n",
    "            'profit_per_decision': pnl['total_profit'] / pnl['num_resolved_decisions']\n",
    "        })\n",
    "\n",
    "    total_pnl.append(pnl)\n",
    "\n",
    "total_pnl = pandas.DataFrame(total_pnl)\n",
    "total_pnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vFZx4hCtx2X"
   },
   "source": [
    "## CrunchDAO Code Interface\n",
    "\n",
    "[Submitting to the CrunchDAO platform requires 2 functions, `train` and `infer`.](https://docs.crunchdao.com/competitions/code-interface) Any line that is not in a function or is not an import will be commented when the notebook is processed.\n",
    "\n",
    "The content of the function is the same as the example, but the train must save the model to be read in infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    We do not recommend using the train function.\n",
    "    \n",
    "    Training should be done before running anything in the cloud environment.\n",
    "    \"\"\"\n",
    "\n",
    "    pass  # no train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(\n",
    "    stream: typing.Iterator[dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Please do not modify the infer function, edit the MyAttacker class directly.\n",
    "\n",
    "    The core of the attacker logic should be implemented through the attacker classes.\n",
    "    \"\"\"\n",
    "\n",
    "    attacker = MyAttacker(num_lags=2, threshold=2.0, burn_in=1000)\n",
    "    total_pnl = zero_pnl_summary()\n",
    "\n",
    "    yield  # mark as ready\n",
    "\n",
    "    for message in stream:\n",
    "        yield attacker.tick_and_predict(x=message['x'])\n",
    "\n",
    "    stream_pnl = attacker.pnl.summary()\n",
    "    total_pnl = add_pnl_summaries(total_pnl, stream_pnl)\n",
    "\n",
    "    if total_pnl['num_resolved_decisions'] > 0:\n",
    "        total_pnl.update({\n",
    "            'profit_per_decision': total_pnl['total_profit'] / total_pnl['num_resolved_decisions']\n",
    "        })\n",
    "\n",
    "    print(total_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crunch.test()\n",
    "\n",
    "print(\"Download this notebook and submit it to the platform: https://hub.crunchdao.com/competitions/mid-one/submit/via/notebook\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyObLpBdl+2mcUOicJdVrKq1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
