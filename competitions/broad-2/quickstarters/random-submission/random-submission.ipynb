{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/broad-2/quickstarters/random-submission/random-submission.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/broad-2/assets/banner.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade crunch-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a new token: https://hub.crunchdao.com/competitions/broad-2/submit/via/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!crunch setup --notebook broad-2 hello --token aaaabbbbccccddddeeeeffff\n",
    "\n",
    "# To retrieve a larger dataset, include the --size large argument as shown below:\n",
    "#!crunch setup --notebook --size large broad-2 hello --token aaaabbbbccccddddeeeeffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spatialdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:52:21.302334Z",
     "start_time": "2024-11-18T09:52:18.268241Z"
    }
   },
   "outputs": [],
   "source": [
    "import spatialdata\n",
    "import scanpy\n",
    "import numpy\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crunch\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:03:44.528694Z",
     "start_time": "2024-11-18T10:03:44.525704Z"
    }
   },
   "outputs": [],
   "source": [
    "def log1p_normalization(arr):\n",
    "    return numpy.log1p((arr/numpy.sum(arr, axis=1, keepdims=True)) * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:04:00.459399Z",
     "start_time": "2024-11-18T10:04:00.455716Z"
    }
   },
   "outputs": [],
   "source": [
    "# In the training function, users build and train the model to make inferences on the test data.\n",
    "# Your model must be stored in the `model_directory_path`.\n",
    "def train(\n",
    "    data_directory_path: str, \n",
    "    model_directory_path: str\n",
    "):    \n",
    "    # Loading scRNAseq data\n",
    "    scRNAseq = scanpy.read_h5ad(os.path.join(data_directory_path, 'Crunch2_scRNAseq.h5ad'))\n",
    "    \n",
    "    # Loading Spatial Data\n",
    "    # UC1_NI.zarr is an example among the available samples. \n",
    "    sdata = spatialdata.read_zarr(os.path.join(data_directory_path, 'UC1_NI.zarr'))\n",
    "        \n",
    "    # TODO Put your train code here!    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:03:59.120294Z",
     "start_time": "2024-11-18T10:03:59.114830Z"
    }
   },
   "outputs": [],
   "source": [
    "# In the inference function, the trained model is loaded and used to make inferences on a\n",
    "# sample of data that matches the characteristics of the training test.\n",
    "def infer(\n",
    "    data_file_path: str,\n",
    "):\n",
    "    data_path = os.path.dirname(data_file_path)\n",
    "    \n",
    "    # Load the list of genes to predict if not already loaded                 \n",
    "    if not hasattr(infer, \"gene_list\"):\n",
    "        print('Loading Genes to predict')\n",
    "        infer.gene_list = pandas.read_csv(os.path.join(data_path, 'Crunch2_gene_list.csv'))        \n",
    "    \n",
    "    gene_names = infer.gene_list['gene_symbols']\n",
    "    \n",
    "    # Load the spatial data file to make predictions\n",
    "    print(f\"Loading spatial data from {data_file_path}...\")\n",
    "    sdata = spatialdata.read_zarr(data_file_path)\n",
    "    \n",
    "    # Identify the cells to predict: cells in 'test' or 'validation' groups \n",
    "    cell_ids = sdata[\"cell_id-group\"].obs.query(\"group == 'test' or group == 'validation'\")[\"cell_id\"]\n",
    "    \n",
    "    # Generate random predictions as a placeholder\n",
    "    # Replace this with the actual model inference  \n",
    "    values = numpy.random.rand(len(cell_ids), len(gene_names))\n",
    "    prediction = pandas.DataFrame(values, index=cell_ids, columns=gene_names)\n",
    "    \n",
    "    # Apply log1p normalization and round to 2 decimal points\n",
    "    prediction.iloc[:, :] = numpy.round(log1p_normalization(prediction.values), 2)    \n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command is running a local test with your submission\n",
    "# making sure that your submission can be accepted by the system\n",
    "crunch.test(\n",
    "    no_determinism_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remember to download this notebook and then submit it at https://hub.crunchdao.com/competitions/broad-2/submit/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
