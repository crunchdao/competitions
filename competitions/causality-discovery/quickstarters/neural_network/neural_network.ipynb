{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd13f4fd",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/causality-discovery/quickstarters/neural_network/neural_network.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bd619",
   "metadata": {
    "id": "125bd619"
   },
   "source": [
    "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/causality-discovery/assets/banner.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84dbaf-74b6-47d6-aa27-ecb3196f1623",
   "metadata": {
    "id": "0e84dbaf-74b6-47d6-aa27-ecb3196f1623",
    "tags": []
   },
   "source": [
    "# Causal Discovery - Neural Network Baseline Notebook\n",
    "\n",
    "This notebook serves two purposes: to introduce the participants to the competition and to provide a simple **neural network**-based submission.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Discovering causal relationships between variables from observational data is crucial in fields such as healthcare and economics. Participants are given datasets with known causal graphs to develop algorithms that uncover the underlying causal structures. The focus is on determining how other variables influence the relationship between two key variables, **`X`** (treatment) and **`Y`** (outcome).\n",
    "\n",
    "## The Solution\n",
    "\n",
    "The core idea of the proposed solution is to design a neural network that takes as input a dataset of observations $N \\times M$ ($N=1000$, $M \\leq 10$) and outputs the adjacency matrix $M \\times M$ representing its causal graph. The proposed neural network architecture is inspired by the [Transformer](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)) model, and aims to capture non-symmetric relationships between variables, thus providing directional information about the arrows between each pair of variables. In addition, this implementation uses *masking* to handle different numbers of variables $N$ in different datasets, ensuring that the input dataset is always modeled as $1000 \\times 10$, with a mask applied when there are fewer than 10 variables. Another key design choice is to make the neural network invariant to both the order of the rows in the input dataset - since the observations have no particular order and are **not** time series - and the order of the variables. The network outputs a (masked) $N \\times N$ matrix of probability values in the range $[0,1]$. A final post-processing step converts the predicted probabilities in each entry of the adjacency matrix to binary values (0s and 1s) to create a DAG using a simple heuristic.\n",
    "\n",
    "The code below contains the following components based on PyTorch and PyTorch Lightning:\n",
    "\n",
    "1. **Dataset Manipulation**: Creates a `PyTorch` dataset from the competition data (`CausalDataset`).\n",
    "\n",
    "2. **Neural Network Architecture**: Defines the neural network architecture and data processing (`CausalModel`), as well as the wrapper (`ModelWrapper`).\n",
    "\n",
    "3. **Heuristics and Graph Functions**: Provides convenience functions to manipulate causal DAGs, including the heuristic to convert predicted probabilities in the adjacency matrix into a DAG.\n",
    "\n",
    "4. **Local Training and Evaluation**: Trains the proposed model locally and evaluates its performance.\n",
    "\n",
    "5. **Submission**: Uses the model within the CrunchDAO submission interface to generate the final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e7a43",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kquOn_FGb73R",
   "metadata": {
    "id": "kquOn_FGb73R"
   },
   "outputs": [],
   "source": [
    "%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a7e5b-5a11-406c-89fc-dfc30fc68205",
   "metadata": {
    "collapsed": true,
    "id": "b37a7e5b-5a11-406c-89fc-dfc30fc68205",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update the token via https://hub.crunchdao.com/competitions/causality-discovery/submit/via/notebook\n",
    "\n",
    "%pip install crunch-cli --upgrade\n",
    "!crunch setup --notebook causality-discovery default --token aaaabbbbccccddddeeeeffff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee3953",
   "metadata": {
    "id": "28ee3953"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50f3f8c-0ee8-44d1-ada9-ab3dfeea7fd6",
   "metadata": {
    "id": "d50f3f8c-0ee8-44d1-ada9-ab3dfeea7fd6"
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Common data science tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch for building and training neural networks\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# We use PyTorch Lightning for training\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# NetworkX for working with graphs\n",
    "import networkx as nx\n",
    "\n",
    "# Scikit-learn for data splitting\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5229074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded inline runner with module: <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "import crunch\n",
    "\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee28a1",
   "metadata": {
    "id": "41ee28a1"
   },
   "source": [
    "### Dataset Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc451ae-13b4-4f8f-a0d5-457c7839d185",
   "metadata": {
    "id": "dfc451ae-13b4-4f8f-a0d5-457c7839d185"
   },
   "outputs": [],
   "source": [
    "class CausalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for handling causal discovery data.\n",
    "\n",
    "    Attributes:\n",
    "        X (np.ndarray): A 3D numpy array of shape (num_samples, 1000, 10) containing the input features.\n",
    "        y (np.ndarray): A 3D numpy array of shape (num_samples, 10, 10) containing the target values.\n",
    "        target_mask (np.ndarray): A 3D boolean numpy array of shape (num_samples, 10, 10) indicating the presence of target values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: typing.List[pd.DataFrame],\n",
    "        y: typing.List[pd.DataFrame]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the dataset with input features and target values.\n",
    "        \"\"\"\n",
    "\n",
    "        # The shape of X is (num_samples, 1000, 10), where 1000 is number of rows and 10 is maximum number of variables\n",
    "        self.X = np.zeros([len(X), 1000, 10], dtype=np.float32)\n",
    "\n",
    "        # The shape of y is (num_samples, 10, 10), where 10 is the maximum number of variables\n",
    "        self.y = np.zeros([len(X), 10, 10], dtype=np.float32)\n",
    "\n",
    "        # The target mask is a boolean array indicating the presence of target values, it is need for model training because not all datasets have 10 variables\n",
    "        self.target_mask = np.zeros([len(X), 10, 10], dtype=bool)\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            self.X[i, :X[i].shape[0], :X[i].shape[1]] = X[i].values\n",
    "            self.y[i, :y[i].shape[0], :y[i].shape[1]] = y[i].values\n",
    "            self.target_mask[i, :y[i].shape[0], :y[i].shape[1]] = True\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieves the sample at the specified index.\n",
    "\n",
    "        Args:\n",
    "            idx: The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing 'X', 'y', and 'target_mask' for the specified index.\n",
    "        \"\"\"\n",
    "\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        target_mask = self.target_mask[idx]\n",
    "\n",
    "        return {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "            'target_mask': target_mask\n",
    "        }\n",
    "\n",
    "\n",
    "def preprocessing(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Preprocesses the input data for neural network.\n",
    "\n",
    "    Args:\n",
    "        X: The input data as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - torch.Tensor: The input data converted to a PyTorch tensor and unsqueezed.\n",
    "            - torch.Tensor: A mask tensor of ones with the same shape as the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = torch.Tensor(X.values).unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6e8d4",
   "metadata": {
    "id": "71e6e8d4"
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef356094",
   "metadata": {
    "id": "ef356094"
   },
   "source": [
    "#### Ideas for Designing the Model Architecture:\n",
    "\n",
    "1. Transform input from (N, M) to (M, M) output.\n",
    "2. Handle a variable number of rows and columns.\n",
    "3. Ensure permutation invariance (for both rows and columns).\n",
    "4. Detect asymmetric relations: $A \\rightarrow B$ ($A$ causes $B$) is different from $B \\rightarrow A$ ($B$ causes $A$)\n",
    "\n",
    "A simple (and effective) example of such an operation is correlation. If you have a pandas DataFrame `df` with shape (N, M) and apply `df.corr()`, it returns an (M, M) correlation matrix. The result remains unchanged if you shuffle the rows or columns.\n",
    "\n",
    "However, correlation is non-directional, meaning `corr(A, B) = corr(B, A)`.\n",
    "\n",
    "In this tutorial notebook, we will use [*scaled Dot-Product Attention*](https://medium.com/@vmirly/tutorial-on-scaled-dot-product-attention-with-pytorch-implementation-from-scratch-66ed898bf817), a module within a standard transformer model. This operation is directional and can transform a tensor from (N, M) to (M, M)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a58dea-3066-41a9-b6ca-9dd184307908",
   "metadata": {
    "id": "81a58dea-3066-41a9-b6ca-9dd184307908"
   },
   "source": [
    "#### Key Parts of the Code\n",
    "\n",
    "1. **CausalModel**:\n",
    "   - This is the main neural network. It processes input data and tries to produce an output that represents relationships between variables.\n",
    "   - The model has two major layers:\n",
    "     - **Input Layer**: This layer transforms the input data using a linear transformation (a fancy way of changing the shape of the data), applies a ReLU activation (to introduce non-linearity), and then applies another linear transformation. The result is split into two parts: `q` (query) and `k` (key).\n",
    "     - **Final Layer**: After processing the data, this layer combines everything and produces the output.\n",
    "   \n",
    "2. **Scaled Dot-Product Attention** (line with `einsum`):\n",
    "  - The key operation here is **Scaled Dot Product Attention**, which helps the model figure out directional relationships between variables.\n",
    "  - This operation uses the query (`q`) and key (`k`) we calculated earlier. The code:\n",
    "    ```python\n",
    "    x = torch.einsum('b s i d, b s j d -> b i j d', q, k) * (x.shape[1] ** -0.5)\n",
    "    ```\n",
    "    performs the attention operation by multiplying the query and key tensors together, where the indices mean `b`: data set, `s`: observation in the data set, `i`: node in the graph (potential cause), `j`: node in the graph (potential consequence), `d`: dimension of the latent representations of the nodes.The query `q` is a latent representation of potential causes; the key `k` is a latent representation of potential consequences; we use different latent representations to be able to separate causes from consequences.\n",
    "    This helps the model learn how different variables interact. The result is scaled by the size of the input, which is a common trick to improve stability during training.\n",
    "\n",
    "3. **ModelWrapper**:\n",
    "   - This is a wrapper that organizes the training process. It makes the model easier to train with PyTorch Lightning.\n",
    "   - It also defines:\n",
    "     - **Loss Function**: The model uses **Binary Cross-Entropy (BCE)**, which is used for tasks where we are predicting yes/no answers (like whether two variables are related or not).\n",
    "     - **Optimizer**: We use the **Adam Optimizer**, which adjusts the weights of the model to improve its predictions.\n",
    "     - **Learning Rate Scheduler**: This reduces the learning rate after 7 epochs (a step in training) to help the model fine-tune its predictions as training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c164314f",
   "metadata": {
    "id": "c164314f"
   },
   "outputs": [],
   "source": [
    "class CausalModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network model for causal discovery.\n",
    "\n",
    "    Attributes:\n",
    "        input_layer (nn.Sequential): The input layer consisting of a linear layer, ReLU activation, and another linear layer.\n",
    "        final (nn.Sequential): The final layer consisting of a linear layer, ReLU activation, and another linear layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: The dimension of the model. Default is 64.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(1, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 2 * d_model)\n",
    "        )\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            The output tensor after applying the model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the query and key tensors\n",
    "        q, k = self.input_layer(x.unsqueeze(-1)).chunk(2, dim=-1)\n",
    "\n",
    "        # Perform the scaled dot-product attention\n",
    "        x = torch.einsum('b s i d, b s j d -> b i j d', q, k) * (x.shape[1] ** -0.5)\n",
    "\n",
    "        y = self.final(x).squeeze(-1)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ModelWrapper(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning Module wrapper for a causal model.\n",
    "\n",
    "    Attributes:\n",
    "        model (CausalModel): The causal model being wrapped.\n",
    "        train_criterion (nn.BCEWithLogitsLoss): The loss function used for training, which is Binary Cross-Entropy with a class weight of 5.0 for the positive class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: The dimension of the model. Default is 64.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = CausalModel(d_model)\n",
    "\n",
    "        # The loss function is Binary Cross-Entropy with a class weight of 5.0 for the positive class, to account for class imbalance.\n",
    "        self.train_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(5.0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler for training.\n",
    "        \"\"\"\n",
    "\n",
    "        # We use the Adam optimizer with a learning rate of 1e-3.\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "        # The learning rate is reduced by a factor of 0.1 after the 7th epoch.\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 7, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, train_batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Defines a single training step, including the computation of the loss and logging.\n",
    "        \"\"\"\n",
    "\n",
    "        x = train_batch['X']\n",
    "        y = train_batch['y']\n",
    "        target_mask = train_batch['target_mask']\n",
    "\n",
    "        preds = self(x)\n",
    "\n",
    "        loss = self.train_criterion(preds[target_mask], y[target_mask])\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d07be9",
   "metadata": {
    "id": "56d07be9"
   },
   "source": [
    "### Heuristics and Graph-Related Functions\n",
    "\n",
    "After obtaining the link probabilities, we need to convert them to binary values (0 or 1) to ensure that the resulting graph satisfies the constraint of being a Directed Acyclic Graph (DAG).\n",
    "\n",
    "In this tutorial, we will use a simple greedy approach:\n",
    "1. Start by defining a directed graph with no edges.\n",
    "2. Add an edge from **X** to **Y**.\n",
    "3. Sort the predicted links by their probability values.\n",
    "4. For each link, add the edge if the probability is greater than 0.5 *and* the graph remains a DAG after the edge is added.\n",
    "\n",
    "We also include functions to label the edges of the DAG that are needed to compute the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb0342c",
   "metadata": {
    "id": "9eb0342c"
   },
   "outputs": [],
   "source": [
    "def transform_proba_to_DAG(\n",
    "    nodes: typing.List[str],\n",
    "    pred: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transforms a probability matrix into a Directed Acyclic Graph (DAG).\n",
    "\n",
    "    Parameters:\n",
    "        nodes: A list of node names.\n",
    "        pred: A 2D numpy array representing the probability matrix.\n",
    "\n",
    "    Returns:\n",
    "        A 2D numpy array representing the adjacency matrix of the DAG.\n",
    "    \"\"\"\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edge('X', 'Y')\n",
    "\n",
    "    x_index, y_index = np.unravel_index(np.argsort(pred.ravel())[::-1], pred.shape)\n",
    "    for i, j in zip(x_index, y_index):\n",
    "        n1 = nodes[i]\n",
    "        n2 = nodes[j]\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        if ((n1 == 'X') and (n2 == 'Y')) or ((n1 == 'Y') and (n2 == 'X')):\n",
    "            continue\n",
    "\n",
    "        if pred[i, j] > 0.5:\n",
    "            G.add_edge(n1, n2)\n",
    "\n",
    "            if not nx.is_directed_acyclic_graph(G):\n",
    "                G.remove_edge(n1, n2)\n",
    "\n",
    "    G = nx.to_numpy_array(G)\n",
    "    return G\n",
    "\n",
    "\n",
    "def graph_nodes_representation(graph, nodelist):\n",
    "    \"\"\"\n",
    "    Create an alternative representation of a graph which is hashable\n",
    "    and equivalent graphs have the same hash.\n",
    "\n",
    "    Python cannot PROPERLY use nx.Graph/DiGraph as key for\n",
    "    dictionaries, because two equivalent graphs with just different\n",
    "    order of the nodes would result in different keys. This is\n",
    "    undesirable here.\n",
    "\n",
    "    So here we transform the graph into an equivalent form that is\n",
    "    based on a specific nodelist and that is hashable. In this way,\n",
    "    two equivalent graphs, once transformed, will result in identical\n",
    "    keys.\n",
    "\n",
    "    So we use the following trick: extract the adjacency matrix\n",
    "    (with nodes in a fixed order) and then make a hashable thing out\n",
    "    of it, through tuple(array.flatten()):\n",
    "    \"\"\"\n",
    "\n",
    "    # This get the adjacency matrix with nodes in a given order, as\n",
    "    # numpy array (which is not hashable):\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph, nodelist=nodelist).todense()\n",
    "\n",
    "    # This transforms the numpy array into a hashable object:\n",
    "    hashable = tuple(adjacency_matrix.flatten())\n",
    "\n",
    "    return hashable\n",
    "\n",
    "\n",
    "def create_graph_label():\n",
    "    \"\"\"\n",
    "    Create a dictionary from graphs to labels, in two formats.\n",
    "    \"\"\"\n",
    "\n",
    "    graph_label = {\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\"), (\"v\", \"Y\")]): \"Confounder\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"Y\", \"v\")]): \"Collider\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"v\", \"Y\")]): \"Mediator\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\")]): \"Cause of X\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"Y\")]): \"Cause of Y\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\")]): \"Consequence of X\",\n",
    "        nx.DiGraph([(\"X\", \"Y\"), (\"Y\", \"v\")]): \"Consequence of Y\",\n",
    "        nx.DiGraph({\"X\": [\"Y\"], \"v\": []}): \"Independent\",\n",
    "    }\n",
    "\n",
    "    nodelist = [\"v\", \"X\", \"Y\"]\n",
    "\n",
    "    # This is an equivalent alternative to graph_label but in a form for which two equivalent graphs have the same key:\n",
    "    adjacency_label = {\n",
    "        graph_nodes_representation(graph, nodelist): label\n",
    "        for graph, label in graph_label.items()\n",
    "    }\n",
    "\n",
    "    return graph_label, adjacency_label\n",
    "\n",
    "\n",
    "def get_labels(adjacency_matrix, adjacency_label):\n",
    "    \"\"\"\n",
    "    Transform an adjacency_matrix (as pd.DataFrame) into a dictionary of variable:label\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "    for variable in adjacency_matrix.columns.drop([\"X\", \"Y\"]):\n",
    "        submatrix = adjacency_matrix.loc[[variable, \"X\", \"Y\"], [variable, \"X\", \"Y\"]]  # this is not hashable\n",
    "        key = tuple(submatrix.values.flatten())  # this is hashable and compatible with adjacency_label\n",
    "\n",
    "        result[variable] = adjacency_label[key]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12186ab4",
   "metadata": {
    "id": "12186ab4"
   },
   "source": [
    "### Local Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9ed5a",
   "metadata": {
    "id": "aea9ed5a"
   },
   "source": [
    "Read the data using crunch api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7984c99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7984c99",
    "outputId": "1a33831c-6303-4b86-d7ca-74dff4283c3d"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = crunch.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da113ad2",
   "metadata": {
    "id": "da113ad2"
   },
   "source": [
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fcb29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a10fcb29",
    "outputId": "929b8b51-2a33-4721-9cc3-9be261213caf"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_keys, test_keys = train_test_split(list(X_train.keys()), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train datasets (top 5):\", train_keys[:5])\n",
    "print(\"Test datasets (top 5):\", test_keys[:5])\n",
    "\n",
    "X_train_split = [X_train[key] for key in train_keys]\n",
    "y_train_split = [y_train[key] for key in train_keys]\n",
    "X_test_split = [X_train[key] for key in test_keys]\n",
    "y_test_split = [y_train[key] for key in test_keys]\n",
    "\n",
    "train_dataset = CausalDataset(X_train_split, y_train_split)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "test_dataset = CausalDataset(X_test_split, y_test_split)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312a99f",
   "metadata": {
    "id": "0312a99f"
   },
   "source": [
    "Train the model using pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3f675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326,
     "referenced_widgets": [
      "e96648c5c5e44ba3a699ae3e4eedb19e",
      "209c6606338c49c5bca01737445fe1c3",
      "c618a013082948bd97942822b63a5712",
      "25e747599ebc4e598ea0c6e7a9af657d",
      "f8b4830d49f74f029f8dcb15db633247",
      "27cf1a24aed34817ad6d6c579443b33a",
      "00c8a881f3a4440f9e57d6144e8c2706",
      "9ef9e67ee48d473cae30f6eee97d3392",
      "521fe81a3aa441fc887aa37cab92fc61",
      "8cc5a7b3cfbe4e4f8fd70184a7d57980",
      "5eec4bb9b399458285f4a727d4115cf6"
     ]
    },
    "id": "f0a3f675",
    "outputId": "c3da1dc8-83c1-439c-f29c-c8474ff2658a"
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model = ModelWrapper(d_model=64)\n",
    "trainer = pl.Trainer(accelerator=\"cpu\", max_epochs=10, logger=True, enable_checkpointing=False, enable_progress_bar=True)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b6b72",
   "metadata": {
    "id": "bf4b6b72"
   },
   "source": [
    "Compute the evaluation score locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "229fe0e7ec684ce58ed6f955d3ff6b87",
      "d7bea8eeca1e48b393db8593c2e46050",
      "9d76d8f95fd048e48f2dad196e426b3a",
      "3d20102f21294199bdb458a28d168541",
      "130b2cdea7cd4192a2117ec32719ce63",
      "5b47b34812c945b1926c71cfee22e8d9",
      "3e2396c1da874d99ae191aab48f3f37c",
      "816cd182722d45cdab3b993a2dea9919",
      "6b0c9b6d733c4457a7512ed5b417da62",
      "195d19f669374c13979e52dff32b5d32",
      "ee0492b343ca4606a573ec3810f8581f"
     ]
    },
    "id": "b103b5b1",
    "outputId": "ba5e5095-c6de-41d1-f6d5-f0f445a3dd07"
   },
   "outputs": [],
   "source": [
    "# Model Inference\n",
    "graph_label, adjacency_label = create_graph_label()\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for name in tqdm(test_keys):\n",
    "    X = X_train[name]\n",
    "    y = y_train[name]\n",
    "    x = preprocessing(X)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)[0]\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "    nodes = list(X.columns)\n",
    "    pred = transform_proba_to_DAG(nodes, pred).astype(int)\n",
    "    A = pd.DataFrame(pred, columns=nodes, index=nodes)\n",
    "\n",
    "    predicted_label = get_labels(A, adjacency_label)\n",
    "    ground_truth_label = get_labels(y, adjacency_label)\n",
    "\n",
    "    for key in predicted_label.keys():\n",
    "        y_pred.append(predicted_label[key])\n",
    "        y_true.append(ground_truth_label[key])\n",
    "\n",
    "y_pred = pd.Series(y_pred)\n",
    "y_true = pd.Series(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b73223",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "64b73223",
    "outputId": "e4137a17-a9f1-458e-9b14-32976e8f773f"
   },
   "outputs": [],
   "source": [
    "# Calculate Balanced Accuracy and Accuracy per class\n",
    "scores = {}\n",
    "\n",
    "for label in y_true.unique():\n",
    "    scores[label] = np.mean(y_pred[y_true == label] == label)\n",
    "\n",
    "scores = pd.Series(scores)\n",
    "scores['Balanced Accuracy'] = scores.mean()\n",
    "\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4177f7",
   "metadata": {
    "id": "6f4177f7"
   },
   "source": [
    "### CrunchDAO Code Interface\n",
    "\n",
    "[Submitting to the CrunchDAO platform requires 2 functions, `train` and `infer`.](https://docs.crunchdao.com/competitions/code-interface) Any line that is not in a function or is not an import will be commented when the notebook is processed.\n",
    "\n",
    "The content of the function is the same as the example, but the train must save the model to be read in infer. This allows for more predictable behavior if the program is restarted without training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ce5f58-0ab6-430a-8ca3-c975689783a0",
   "metadata": {
    "id": "89ce5f58-0ab6-430a-8ca3-c975689783a0"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    X_train: typing.Dict[str, pd.DataFrame],\n",
    "    y_train: typing.Dict[str, pd.DataFrame],\n",
    "    # number_of_features: int,\n",
    "    model_directory_path: str,\n",
    "    # id_column_name: str,\n",
    "    # prediction_column_name: str,\n",
    "    # has_gpu: bool,\n",
    ") -> None:\n",
    "    X = []\n",
    "    y = []\n",
    "    for dataset_id in X_train:\n",
    "        X.append(X_train[dataset_id])\n",
    "        y.append(y_train[dataset_id])\n",
    "\n",
    "    dataset = CausalDataset(X,y)\n",
    "    train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "    model = ModelWrapper(d_model=64)\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"cpu\",\n",
    "        max_epochs=10,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "    trainer.fit(model, train_dataloader)\n",
    "\n",
    "    model_path_file = os.path.join(model_directory_path, \"model.pt\")\n",
    "    torch.save(model.model.state_dict(), model_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbff5b28-37ec-4cec-bf20-48ea77d13ba2",
   "metadata": {
    "id": "fbff5b28-37ec-4cec-bf20-48ea77d13ba2"
   },
   "outputs": [],
   "source": [
    "# Uncomment what you need!\n",
    "def infer(\n",
    "    X_test: typing.Dict[str, pd.DataFrame],\n",
    "    # number_of_features: int,\n",
    "    model_directory_path: str,\n",
    "    id_column_name: str,\n",
    "    prediction_column_name: str,\n",
    "    # has_gpu: bool,\n",
    "    # has_trained: bool,\n",
    ") -> pd.DataFrame:\n",
    "    model_path_file = os.path.join(model_directory_path, \"model.pt\")\n",
    "\n",
    "    model = CausalModel(d_model=64)\n",
    "    model = model.eval()\n",
    "    model.load_state_dict(torch.load(model_path_file, map_location='cpu'))\n",
    "\n",
    "    submission_file = {}\n",
    "    for name in X_test:\n",
    "        X = X_test[name]\n",
    "        x = preprocessing(X)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)[0]\n",
    "            pred = torch.sigmoid(pred)\n",
    "            pred = pred.cpu().numpy()\n",
    "\n",
    "        nodes = list(X.columns)\n",
    "        pred = transform_proba_to_DAG(nodes, pred).astype(int)\n",
    "        G = pd.DataFrame(pred, columns=nodes, index=nodes)\n",
    "\n",
    "        for i in nodes:\n",
    "            for j in nodes:\n",
    "                submission_file[f'{name}_{i}_{j}'] = int(G.loc[i,j])\n",
    "\n",
    "    submission_file = pd.Series(submission_file)\n",
    "    submission_file = submission_file.reset_index()\n",
    "    submission_file.columns = [id_column_name, prediction_column_name]\n",
    "\n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026eb51",
   "metadata": {
    "id": "3026eb51"
   },
   "source": [
    "#### Local Testing\n",
    "\n",
    "Before submitting your notebook, please make sure that it works locally so that you do not waste compute time. The `crunch.test()` will execute your code with the same logic as it will in the cloud environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f2ccc-43f0-4931-b731-9ae181c1d768",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d64f2ccc-43f0-4931-b731-9ae181c1d768",
    "outputId": "3550ff0d-ab88-4ae9-d71b-f39110c90614",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crunch.test(\n",
    "    no_determinism_check=True\n",
    ")\n",
    "\n",
    "print(\"Download this notebook and submit it to the platform: https://hub.crunchdao.com/competitions/causality-discovery/submit/via/notebook\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c8a881f3a4440f9e57d6144e8c2706": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "130b2cdea7cd4192a2117ec32719ce63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "195d19f669374c13979e52dff32b5d32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "209c6606338c49c5bca01737445fe1c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27cf1a24aed34817ad6d6c579443b33a",
      "placeholder": "​",
      "style": "IPY_MODEL_00c8a881f3a4440f9e57d6144e8c2706",
      "value": "Epoch 1: 100%"
     }
    },
    "229fe0e7ec684ce58ed6f955d3ff6b87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7bea8eeca1e48b393db8593c2e46050",
       "IPY_MODEL_9d76d8f95fd048e48f2dad196e426b3a",
       "IPY_MODEL_3d20102f21294199bdb458a28d168541"
      ],
      "layout": "IPY_MODEL_130b2cdea7cd4192a2117ec32719ce63"
     }
    },
    "25e747599ebc4e598ea0c6e7a9af657d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cc5a7b3cfbe4e4f8fd70184a7d57980",
      "placeholder": "​",
      "style": "IPY_MODEL_5eec4bb9b399458285f4a727d4115cf6",
      "value": " 293/293 [17:12&lt;00:00,  0.28it/s, v_num=1, train_loss_step=0.852, train_loss_epoch=0.893]"
     }
    },
    "27cf1a24aed34817ad6d6c579443b33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d20102f21294199bdb458a28d168541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_195d19f669374c13979e52dff32b5d32",
      "placeholder": "​",
      "style": "IPY_MODEL_ee0492b343ca4606a573ec3810f8581f",
      "value": " 4700/4700 [02:21&lt;00:00, 32.57it/s]"
     }
    },
    "3e2396c1da874d99ae191aab48f3f37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "521fe81a3aa441fc887aa37cab92fc61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b47b34812c945b1926c71cfee22e8d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eec4bb9b399458285f4a727d4115cf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b0c9b6d733c4457a7512ed5b417da62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "816cd182722d45cdab3b993a2dea9919": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cc5a7b3cfbe4e4f8fd70184a7d57980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d76d8f95fd048e48f2dad196e426b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_816cd182722d45cdab3b993a2dea9919",
      "max": 4700,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b0c9b6d733c4457a7512ed5b417da62",
      "value": 4700
     }
    },
    "9ef9e67ee48d473cae30f6eee97d3392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c618a013082948bd97942822b63a5712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ef9e67ee48d473cae30f6eee97d3392",
      "max": 293,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_521fe81a3aa441fc887aa37cab92fc61",
      "value": 293
     }
    },
    "d7bea8eeca1e48b393db8593c2e46050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b47b34812c945b1926c71cfee22e8d9",
      "placeholder": "​",
      "style": "IPY_MODEL_3e2396c1da874d99ae191aab48f3f37c",
      "value": "100%"
     }
    },
    "e96648c5c5e44ba3a699ae3e4eedb19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_209c6606338c49c5bca01737445fe1c3",
       "IPY_MODEL_c618a013082948bd97942822b63a5712",
       "IPY_MODEL_25e747599ebc4e598ea0c6e7a9af657d"
      ],
      "layout": "IPY_MODEL_f8b4830d49f74f029f8dcb15db633247"
     }
    },
    "ee0492b343ca4606a573ec3810f8581f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8b4830d49f74f029f8dcb15db633247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
